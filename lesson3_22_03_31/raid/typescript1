vagrant@raid-hw3:~$ script
Script started, file is typescript
vagrant@raid-hw3:~$ fdisk -l
fdisk: cannot open /dev/sdb: Permission denied
fdisk: cannot open /dev/sda: Permission denied
fdisk: cannot open /dev/sdc: Permission denied
fdisk: cannot open /dev/sdd: Permission denied
vagrant@raid-hw3:~$ sudo fdisk -l
Disk /dev/sdb: 10 MiB, 10485760 bytes, 20480 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/sda: 40 GiB, 42949672960 bytes, 83886080 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disklabel type: dos
Disk identifier: 0x8c73b2c7

Device     Boot Start      End  Sectors Size Id Type
/dev/sda1  *     2048 83886046 83883999  40G 83 Linux


Disk /dev/sdc: 5 GiB, 5368709120 bytes, 10485760 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes


Disk /dev/sdd: 3 GiB, 3221225472 bytes, 6291456 sectors
Units: sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
vagrant@raid-hw3:~$ sudo df -k
Filesystem         1K-blocks      Used Available Use% Mounted on
udev                  233392         0    233392   0% /dev
tmpfs                  49264       624     48640   2% /run
/dev/sda1           40593612   1155780  39421448   3% /
tmpfs                 246304         0    246304   0% /dev/shm
tmpfs                   5120         0      5120   0% /run/lock
tmpfs                 246304         0    246304   0% /sys/fs/cgroup
vagrant            788936004 260850804 528085200  34% /vagrant
home_vagrant_share 788936004 260850804 528085200  34% /home/vagrant/share
tmpfs                  49260         0     49260   0% /run/user/1000
vagrant@raid-hw3:~$ sudo fdisk /dev/sdc

Welcome to fdisk (util-linux 2.31.1).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table.
Created a new DOS disklabel with disk identifier 0x955a1028.

Command (m for help): m

Help:

  DOS (MBR)
   a   toggle a bootable flag
   b   edit nested BSD disklabel
   c   toggle the dos compatibility flag

  Generic
   d   delete a partition
   F   list free unpartitioned space
   l   list known partition types
   n   add a new partition
   p   print the partition table
   t   change a partition type
   v   verify the partition table
   i   print information about a partition

  Misc
   m   print this menu
   u   change display/entry units
   x   extra functionality (experts only)

  Script
   I   load disk layout from sfdisk script file
   O   dump disk layout to sfdisk script file

  Save & Exit
   w   write table to disk and exit
   q   quit without saving changes

  Create a new label
   g   create a new empty GPT partition table
   G   create a new empty SGI (IRIX) partition table
   o   create a new empty DOS partition table
   s   create a new empty Sun partition table


Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (1-4, default 1): 1
First sector (2048-10485759, default 2048):
Last sector, +sectors or +size{K,M,G,T,P} (2048-10485759, default 10485759):

Created a new partition 1 of type 'Linux' and of size 5 GiB.

Command (m for help): t
Selected partition 1
Hex code (type L to list all codes): L

 0  Empty           24  NEC DOS         81  Minix / old Lin bf  Solaris
 1  FAT12           27  Hidden NTFS Win 82  Linux swap / So c1  DRDOS/sec (FAT-
 2  XENIX root      39  Plan 9          83  Linux           c4  DRDOS/sec (FAT-
 3  XENIX usr       3c  PartitionMagic  84  OS/2 hidden or  c6  DRDOS/sec (FAT-
 4  FAT16 <32M      40  Venix 80286     85  Linux extended  c7  Syrinx
 5  Extended        41  PPC PReP Boot   86  NTFS volume set da  Non-FS data
 6  FAT16           42  SFS             87  NTFS volume set db  CP/M / CTOS / .
 7  HPFS/NTFS/exFAT 4d  QNX4.x          88  Linux plaintext de  Dell Utility
 8  AIX             4e  QNX4.x 2nd part 8e  Linux LVM       df  BootIt
 9  AIX bootable    4f  QNX4.x 3rd part 93  Amoeba          e1  DOS access
 a  OS/2 Boot Manag 50  OnTrack DM      94  Amoeba BBT      e3  DOS R/O
 b  W95 FAT32       51  OnTrack DM6 Aux 9f  BSD/OS          e4  SpeedStor
 c  W95 FAT32 (LBA) 52  CP/M            a0  IBM Thinkpad hi ea  Rufus alignment
 e  W95 FAT16 (LBA) 53  OnTrack DM6 Aux a5  FreeBSD         eb  BeOS fs
 f  W95 Ext'd (LBA) 54  OnTrackDM6      a6  OpenBSD         ee  GPT
10  OPUS            55  EZ-Drive        a7  NeXTSTEP        ef  EFI (FAT-12/16/
11  Hidden FAT12    56  Golden Bow      a8  Darwin UFS      f0  Linux/PA-RISC b
12  Compaq diagnost 5c  Priam Edisk     a9  NetBSD          f1  SpeedStor
14  Hidden FAT16 <3 61  SpeedStor       ab  Darwin boot     f4  SpeedStor
16  Hidden FAT16    63  GNU HURD or Sys af  HFS / HFS+      f2  DOS secondary
17  Hidden HPFS/NTF 64  Novell Netware  b7  BSDI fs         fb  VMware VMFS
18  AST SmartSleep  65  Novell Netware  b8  BSDI swap       fc  VMware VMKCORE
1b  Hidden W95 FAT3 70  DiskSecure Mult bb  Boot Wizard hid fd  Linux raid auto
1c  Hidden W95 FAT3 75  PC/IX           bc  Acronis FAT32 L fe  LANstep
1e  Hidden W95 FAT1 80  Old Minix       be  Solaris boot    ff  BBT
Hex code (type L to list all codes): fd
Changed type of partition 'Linux' to 'Linux raid autodetect'.

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.

vagrant@raid-hw3:~$ sudo fdisk /dev/sdd

Welcome to fdisk (util-linux 2.31.1).
Changes will remain in memory only, until you decide to write them.
Be careful before using the write command.

Device does not contain a recognized partition table.
Created a new DOS disklabel with disk identifier 0x9f56cd52.

Command (m for help): n
Partition type
   p   primary (0 primary, 0 extended, 4 free)
   e   extended (container for logical partitions)
Select (default p): p
Partition number (1-4, default 1):
First sector (2048-6291455, default 2048):
Last sector, +sectors or +size{K,M,G,T,P} (2048-6291455, default 6291455):

Created a new partition 1 of type 'Linux' and of size 3 GiB.

Command (m for help): t
Selected partition 1
Hex code (type L to list all codes): fd
Changed type of partition 'Linux' to 'Linux raid autodetect'.

Command (m for help): w
The partition table has been altered.
Calling ioctl() to re-read partition table.
Syncing disks.

vagrant@raid-hw3:~$ lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0  40G  0 disk
└─sda1   8:1    0  40G  0 part /
sdb      8:16   0  10M  0 disk
sdc      8:32   0   5G  0 disk
└─sdc1   8:33   0   5G  0 part
sdd      8:48   0   3G  0 disk
└─sdd1   8:49   0   3G  0 part
vagrant@raid-hw3:~$  sudo mdadm --create --verbose /dev/md0 --level=0  --raid-devices=2 /dev/sdc1 /dev/sdd1
mdadm: chunk size defaults to 512K
mdadm: Defaulting to version 1.2 metadata
mdadm: array /dev/md0 started.
vagrant@raid-hw3:~$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE  MOUNTPOINT
sda       8:0    0  40G  0 disk
└─sda1    8:1    0  40G  0 part  /
sdb       8:16   0  10M  0 disk
sdc       8:32   0   5G  0 disk
└─sdc1    8:33   0   5G  0 part
  └─md0   9:0    0   8G  0 raid0
sdd       8:48   0   3G  0 disk
└─sdd1    8:49   0   3G  0 part
  └─md0   9:0    0   8G  0 raid0
vagrant@raid-hw3:~$ sudo mkfs.ext4 /dev/md0
mke2fs 1.44.1 (24-Mar-2018)
Creating filesystem with 2094080 4k blocks and 524288 inodes
Filesystem UUID: 9a433191-2ca2-4879-bef3-79d5902ffed6
Superblock backups stored on blocks:
        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632

Allocating group tables: done
Writing inode tables: done
Creating journal (16384 blocks): done
Writing superblocks and filesystem accounting information: done

vagrant@raid-hw3:~$ sudo cat /etc/mdadm/mdadm.conf
# mdadm.conf
#
# !NB! Run update-initramfs -u after updating this file.
# !NB! This will ensure that initramfs has an uptodate copy.
#
# Please refer to mdadm.conf(5) for information about this file.
#

# by default (built-in), scan all partitions (/proc/partitions) and all
# containers for MD superblocks. alternatively, specify devices to scan, using
# wildcards if desired.
#DEVICE partitions containers

# automatically tag new arrays as belonging to the local system
HOMEHOST <system>

# instruct the monitoring daemon where to send mail alerts
MAILADDR root

# definitions of existing MD arrays

# This configuration was auto-generated on Fri, 25 Mar 2022 14:16:52 +0000 by mkconf
vagrant@raid-hw3:~$ sudo mdadm --detail --scan --verbose
ARRAY /dev/md0 level=raid0 num-devices=2 metadata=1.2 name=raid-hw3:0 UUID=24427bcc:8046def4:98a78b51:85034e83
   devices=/dev/sdc1,/dev/sdd1
vagrant@raid-hw3:~$ echo "DEVICE partitions" >> /etc/mdadm/mdadm.conf
bash: /etc/mdadm/mdadm.conf: Permission denied
vagrant@raid-hw3:~$ sudo echo "DEVICE partitions" >> /etc/mdadm/mdadm.conf
bash: /etc/mdadm/mdadm.conf: Permission denied
vagrant@raid-hw3:~$ sudo -i echo "DEVICE partitions" >> /etc/mdadm/mdadm.conf
bash: /etc/mdadm/mdadm.conf: Permission denied
vagrant@raid-hw3:~$ su echo "DEVICE partitions" >> /etc/mdadm/mdadm.conf
bash: /etc/mdadm/mdadm.conf: Permission denied
vagrant@raid-hw3:~$ su root
Password:
su: Authentication failure
vagrant@raid-hw3:~$ su root
Password:
su: Authentication failure
vagrant@raid-hw3:~$ su root
Password:
su: Authentication failure
vagrant@raid-hw3:~$ su echo "DEVICE partitions" > /etc/mdadm/mdadm.conf
bash: /etc/mdadm/mdadm.conf: Permission denied
vagrant@raid-hw3:~$ su root
Password:
su: Authentication failure
vagrant@raid-hw3:~$ su root
Password:
usu: Authentication failure
vagrant@raid-hw3:~$ ubuntu
ubuntu: command not found
vagrant@raid-hw3:~$ su root
Password:
su: Authentication failure
vagrant@raid-hw3:~$ sudo nano /etc/shadow
vagrant@raid-hw3:~$ passwd root
passwd: You may not view or modify password information for root.
vagrant@raid-hw3:~$ sudo passwd root
Enter new UNIX password:
Retype new UNIX password:
passwd: password updated successfully
vagrant@raid-hw3:~$ su root
Password:
root@raid-hw3:/home/vagrant# echo "DEVICE partitions" >> /etc/mdadm/mdadm.conf
root@raid-hw3:/home/vagrant# mdadm --detail --scan --verbose | awk '/ARRAY/ {print}' >> /etc/mdadm/mdadm.conf
root@raid-hw3:/home/vagrant# cat /etc/mdadm/mdadm.conf
# mdadm.conf
#
# !NB! Run update-initramfs -u after updating this file.
# !NB! This will ensure that initramfs has an uptodate copy.
#
# Please refer to mdadm.conf(5) for information about this file.
#

# by default (built-in), scan all partitions (/proc/partitions) and all
# containers for MD superblocks. alternatively, specify devices to scan, using
# wildcards if desired.
#DEVICE partitions containers

# automatically tag new arrays as belonging to the local system
HOMEHOST <system>

# instruct the monitoring daemon where to send mail alerts
MAILADDR root

# definitions of existing MD arrays

# This configuration was auto-generated on Fri, 25 Mar 2022 14:16:52 +0000 by mkconf
DEVICE partitions
ARRAY /dev/md0 level=raid0 num-devices=2 metadata=1.2 name=raid-hw3:0 UUID=24427bcc:8046def4:98a78b51:85034e83
root@raid-hw3:/home/vagrant# mkdir /mnt/raid
root@raid-hw3:/home/vagrant# mount /dev/md0 /mnt/raid
root@raid-hw3:/home/vagrant# nano /etc/fstab
root@raid-hw3:/home/vagrant# cat /etc/fstab
LABEL=cloudimg-rootfs   /        ext4   defaults        0 1
#VAGRANT-BEGIN
# The contents below are automatically generated by Vagrant. Do not modify.
home_vagrant_share /home/vagrant/share vboxsf uid=1000,gid=1000,_netdev 0 0
vagrant /vagrant vboxsf uid=1000,gid=1000,_netdev 0 0
#VAGRANT-END

/dev/md0        /mnt/raid       ext4    defaults        1 2
root@raid-hw3:/home/vagrant# touch file1 /mnt/raid
root@raid-hw3:/home/vagrant# touch file2 /mnt/raid
root@raid-hw3:/home/vagrant# touch file3 /mnt/raid
root@raid-hw3:/home/vagrant# ls /mnt/raid
lost+found
root@raid-hw3:/home/vagrant# touch file1 /mnt/raid/
root@raid-hw3:/home/vagrant# ls /mnt/raid
lost+found
root@raid-hw3:/home/vagrant# ls /mnt
raid
root@raid-hw3:/home/vagrant# ls /mnt/raid
lost+found
root@raid-hw3:/home/vagrant# cd /mnt/raid
root@raid-hw3:/mnt/raid# touch file1
root@raid-hw3:/mnt/raid# touch file2
root@raid-hw3:/mnt/raid# touch file3
root@raid-hw3:/mnt/raid# ls /mnt/raid
file1  file2  file3  lost+found
root@raid-hw3:/mnt/raid# update-initramfs -u
update-initramfs: Generating /boot/initrd.img-4.15.0-173-generic
root@raid-hw3:/mnt/raid# lsblk
NAME    MAJ:MIN RM SIZE RO TYPE  MOUNTPOINT
sda       8:0    0  40G  0 disk
└─sda1    8:1    0  40G  0 part  /
sdb       8:16   0  10M  0 disk
sdc       8:32   0   5G  0 disk
└─sdc1    8:33   0   5G  0 part
  └─md0   9:0    0   8G  0 raid0 /mnt/raid
sdd       8:48   0   3G  0 disk
└─sdd1    8:49   0   3G  0 part
  └─md0   9:0    0   8G  0 raid0 /mnt/raid
root@raid-hw3:/mnt/raid# cat /proc/mdstat
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid0 sdd1[1] sdc1[0]
      8376320 blocks super 1.2 512k chunks

unused devices: <none>
root@raid-hw3:/mnt/raid# echo 'check' >/sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/mnt/raid# mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
root@raid-hw3:/mnt/raid# umount /mnt/raid
umount: /mnt/raid: target is busy.
root@raid-hw3:/mnt/raid# mdadm --detail /dev/md0
/dev/md0:
           Version : 1.2
     Creation Time : Sun Apr  3 19:31:55 2022
        Raid Level : raid0
        Array Size : 8376320 (7.99 GiB 8.58 GB)
      Raid Devices : 2
     Total Devices : 2
       Persistence : Superblock is persistent

       Update Time : Sun Apr  3 19:31:55 2022
             State : clean
    Active Devices : 2
   Working Devices : 2
    Failed Devices : 0
     Spare Devices : 0

        Chunk Size : 512K

Consistency Policy : none

              Name : raid-hw3:0  (local to host raid-hw3)
              UUID : 24427bcc:8046def4:98a78b51:85034e83
            Events : 0

    Number   Major   Minor   RaidDevice State
       0       8       33        0      active sync   /dev/sdc1
       1       8       49        1      active sync   /dev/sdd1
root@raid-hw3:/mnt/raid# mdadm --detail --scan >> /etc/mdadm.conf
root@raid-hw3:/mnt/raid# mdadm --detail --scan /dev/md0
ARRAY /dev/md0 metadata=1.2 name=raid-hw3:0 UUID=24427bcc:8046def4:98a78b51:85034e83
root@raid-hw3:/mnt/raid# mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
root@raid-hw3:/mnt/raid# mdadm /dev/md0 --fail /dev/sdd1
mdadm: set device faulty failed for /dev/sdd1:  Device or resource busy
root@raid-hw3:/mnt/raid# cat /proc/mdstat
Personalities : [linear] [multipath] [raid0] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid0 sdd1[1] sdc1[0]
      8376320 blocks super 1.2 512k chunks

unused devices: <none>
root@raid-hw3:/mnt/raid# fuser -cuk /mnt/raid
/mnt/raid:            2231c(root)
vagrant@raid-hw3:~$ sudo mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
vagrant@raid-hw3:~$ logout
bash: logout: not login shell: use `exit'
vagrant@raid-hw3:~$ exit
Script done, file is typescript
vagrant@raid-hw3:~$ mv ~/typescript ~/share/
vagrant@raid-hw3:~$ exit
logout
Connection to 192.168.23.20 closed.
PS C:\tms\lesson3\raid> vagrant reload
==> vagrant: You have requested to enabled the experimental flag with the following features:
==> vagrant:
==> vagrant: Features:  disks
==> vagrant:
==> vagrant: Please use with caution, as some of the features may not be fully
==> vagrant: functional yet.
==> raid-learn: Attempting graceful shutdown of VM...
==> raid-learn: Checking if box 'ubuntu/bionic64' version '20220325.0.0' is up to date...
==> raid-learn: There was a problem while downloading the metadata for your box
==> raid-learn: to check for updates. This is not an error, since it is usually due
==> raid-learn: to temporary network problems. This is just a warning. The problem
==> raid-learn: encountered was:
==> raid-learn:
==> raid-learn: The requested URL returned error: 404
==> raid-learn:
==> raid-learn: If you want to check for box updates, verify your network connection
==> raid-learn: is valid and try again.
==> raid-learn: Clearing any previously set forwarded ports...
==> raid-learn: Clearing any previously set network interfaces...
==> raid-learn: Preparing network interfaces based on configuration...
    raid-learn: Adapter 1: nat
    raid-learn: Adapter 2: hostonly
==> raid-learn: Forwarding ports...
    raid-learn: 22 (guest) => 2222 (host) (adapter 1)
==> raid-learn: Configuring storage mediums...
==> raid-learn: Running 'pre-boot' VM customizations...
==> raid-learn: Booting VM...
==> raid-learn: Waiting for machine to boot. This may take a few minutes...
    raid-learn: SSH address: 127.0.0.1:2222
    raid-learn: SSH username: vagrant
    raid-learn: SSH auth method: private key
==> raid-learn: Machine booted and ready!
==> raid-learn: Checking for guest additions in VM...
    raid-learn: The guest additions on this VM do not match the installed version of
    raid-learn: VirtualBox! In most cases this is fine, but in rare cases it can
    raid-learn: prevent things such as shared folders from working properly. If you see
    raid-learn: shared folder errors, please make sure the guest additions within the
    raid-learn: virtual machine match the version of VirtualBox you have installed on
    raid-learn: your host and reload your VM.
    raid-learn:
    raid-learn: Guest Additions Version: 5.2.42
    raid-learn: VirtualBox Version: 6.1
==> raid-learn: Setting hostname...
==> raid-learn: Configuring and enabling network interfaces...
==> raid-learn: Mounting shared folders...
    raid-learn: /vagrant => C:/tms/lesson3/raid
    raid-learn: /home/vagrant/share => C:/tms/lesson3/raid/share
==> raid-learn: Machine already provisioned. Run `vagrant provision` or use the `--provision`
==> raid-learn: flag to force provisioning. Provisioners marked to run always will still run.
PS C:\tms\lesson3\raid> ssh raid-hw3
Enter passphrase for key 'C:\Users\demix/.ssh/tms_ssh':
Welcome to Ubuntu 18.04.6 LTS (GNU/Linux 4.15.0-173-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Sun Apr  3 20:25:22 UTC 2022

  System load:  0.87              Processes:             91
  Usage of /:   2.9% of 38.71GB   Users logged in:       0
  Memory usage: 24%               IP address for enp0s3: 10.0.2.15
  Swap usage:   0%                IP address for enp0s8: 192.168.23.20


0 updates can be applied immediately.

New release '20.04.4 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Last login: Sun Apr  3 18:08:46 2022 from 192.168.23.1
vagrant@raid-hw3:~$ cat ~/.ssh/authorized_key
cat: /home/vagrant/.ssh/authorized_key: No such file or directory
vagrant@raid-hw3:~$ cat ~/.ssh/authorized_keys
ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQDD63UUDRiA/UhrRMP903JkZhJ4UzN9mfbbKe/zCIr5w0lDNqHLZNi141K7qbvgUM1tm4TvTnnW2OIGLW+TdB4/FCG+fasqOxF+bw2GR/buBm+ShDtBmXme9UMHL+s2kfhqqGxYKNMvcMqBjaVVi7aPZTq0z8lYaFmVX/kOnCn09vmTFV/rVOoVPfRML3BgymazcmKkOOBlZyULV8+BOVT4MuUpA1g4kpVn7zCWnK8W49rYFdtpWIvcQ6ysEw4LtcXrEDmmAsv7S1RVWxhiliPJIvftKWdi37ZTeYRpEbksm1O2j99ckQPWnBnLeHjUCIfbxIqMrwFZ0zXIKTc+2nRD vagrant
ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIIu8sf0cWURB8WXZl7ZxwFfR1C5lPM9dbuxDHVB36R5W kodzimo@gmail.com
vagrant@raid-hw3:~$ script
Script started, file is typescript
vagrant@raid-hw3:~$ sudo mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
vagrant@raid-hw3:~$ cat /proc/mdstat
Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid0 sdd1[1] sdc1[0]
      8376320 blocks super 1.2 512k chunks

unused devices: <none>
vagrant@raid-hw3:~$ sudo lsof | grep '/mnt/raid'
vagrant@raid-hw3:~$ sudo umount -l /mnt/raid
vagrant@raid-hw3:~$ sudo umount -f /mnt/raid
umount: /mnt/raid: not mounted.
vagrant@raid-hw3:~$ sudo mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
vagrant@raid-hw3:~$ sudo nano /etc/mdadm/mdadm.conf
vagrant@raid-hw3:~$ sudo nano /etc/mdadm/mdadm.conf
vagrant@raid-hw3:~$ ls /mnt/raid
vagrant@raid-hw3:~$ sudo ls /mnt/raid
vagrant@raid-hw3:~$ sudo ls /etc/fstab
/etc/fstab
vagrant@raid-hw3:~$ sudo nano /etc/fstab
vagrant@raid-hw3:~$ lsblk
NAME    MAJ:MIN RM SIZE RO TYPE  MOUNTPOINT
sda       8:0    0  40G  0 disk
└─sda1    8:1    0  40G  0 part  /
sdb       8:16   0  10M  0 disk
sdc       8:32   0   5G  0 disk
└─sdc1    8:33   0   5G  0 part
  └─md0   9:0    0   8G  0 raid0
sdd       8:48   0   3G  0 disk
└─sdd1    8:49   0   3G  0 part
  └─md0   9:0    0   8G  0 raid0
vagrant@raid-hw3:~$ sudo update-initramfs -u
update-initramfs: Generating /boot/initrd.img-4.15.0-173-generic
vagrant@raid-hw3:~$ logout
bash: logout: not login shell: use `exit'
vagrant@raid-hw3:~$ exit
exit
Script done, file is typescript
vagrant@raid-hw3:~$ logout
Connection to 192.168.23.20 closed.
PS C:\tms\lesson3\raid> vagrant reload
==> vagrant: You have requested to enabled the experimental flag with the following features:
==> vagrant:
==> vagrant: Features:  disks
==> vagrant:
==> vagrant: Please use with caution, as some of the features may not be fully
==> vagrant: functional yet.
==> raid-learn: Attempting graceful shutdown of VM...
==> raid-learn: Checking if box 'ubuntu/bionic64' version '20220325.0.0' is up to date...
==> raid-learn: Clearing any previously set forwarded ports...
==> raid-learn: Clearing any previously set network interfaces...
==> raid-learn: Preparing network interfaces based on configuration...
    raid-learn: Adapter 1: nat
    raid-learn: Adapter 2: hostonly
==> raid-learn: Forwarding ports...
    raid-learn: 22 (guest) => 2222 (host) (adapter 1)
==> raid-learn: Configuring storage mediums...
==> raid-learn: Running 'pre-boot' VM customizations...
==> raid-learn: Booting VM...
==> raid-learn: Waiting for machine to boot. This may take a few minutes...
    raid-learn: SSH address: 127.0.0.1:2222
    raid-learn: SSH username: vagrant
    raid-learn: SSH auth method: private key
==> raid-learn: Machine booted and ready!
==> raid-learn: Checking for guest additions in VM...
    raid-learn: The guest additions on this VM do not match the installed version of
    raid-learn: VirtualBox! In most cases this is fine, but in rare cases it can
    raid-learn: prevent things such as shared folders from working properly. If you see
    raid-learn: shared folder errors, please make sure the guest additions within the
    raid-learn: virtual machine match the version of VirtualBox you have installed on
    raid-learn: your host and reload your VM.
    raid-learn:
    raid-learn: Guest Additions Version: 5.2.42
    raid-learn: VirtualBox Version: 6.1
==> raid-learn: Setting hostname...
==> raid-learn: Configuring and enabling network interfaces...
==> raid-learn: Mounting shared folders...
    raid-learn: /vagrant => C:/tms/lesson3/raid
    raid-learn: /home/vagrant/share => C:/tms/lesson3/raid/share
==> raid-learn: Machine already provisioned. Run `vagrant provision` or use the `--provision`
==> raid-learn: flag to force provisioning. Provisioners marked to run always will still run.
PS C:\tms\lesson3\raid> ssh raid-hw3
Enter passphrase for key 'C:\Users\demix/.ssh/tms_ssh':
Welcome to Ubuntu 18.04.6 LTS (GNU/Linux 4.15.0-173-generic x86_64)

 * Documentation:  https://help.ubuntu.com
 * Management:     https://landscape.canonical.com
 * Support:        https://ubuntu.com/advantage

  System information as of Sun Apr  3 20:40:06 UTC 2022

  System load:  0.65              Processes:             94
  Usage of /:   2.9% of 38.71GB   Users logged in:       0
  Memory usage: 24%               IP address for enp0s3: 10.0.2.15
  Swap usage:   0%                IP address for enp0s8: 192.168.23.20


0 updates can be applied immediately.

New release '20.04.4 LTS' available.
Run 'do-release-upgrade' to upgrade to it.


Last login: Sun Apr  3 20:25:23 2022 from 192.168.23.1
vagrant@raid-hw3:~$ sudo mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
vagrant@raid-hw3:~$ sudo mount /dev/md0 /mnt/raid
mount: /mnt/raid: /dev/md0 already mounted on /mnt/raid.
vagrant@raid-hw3:~$ ls /mnt/raid
file1  file2  file3  lost+found
vagrant@raid-hw3:~$ sudo ls /etc/fstab
/etc/fstab
vagrant@raid-hw3:~$ sudo cat /etc/fstab
LABEL=cloudimg-rootfs   /        ext4   defaults        0 1

/dev/md0        /mnt/raid       ext4    defaults        1 2
#VAGRANT-BEGIN
# The contents below are automatically generated by Vagrant. Do not modify.
home_vagrant_share /home/vagrant/share vboxsf uid=1000,gid=1000,_netdev 0 0
vagrant /vagrant vboxsf uid=1000,gid=1000,_netdev 0 0
#VAGRANT-END
vagrant@raid-hw3:~$ sudo nano /etc/fstab
vagrant@raid-hw3:~$ umount /mnt/raid
umount: /mnt/raid: umount failed: Operation not permitted.
vagrant@raid-hw3:~$ sudo umount /mnt/raid
vagrant@raid-hw3:~$ sudo mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
vagrant@raid-hw3:~$ sudo watch cat /proc/mdstat
vagrant@raid-hw3:~$ vagrant@raid-hw3:~$ sudo echo 'check' >/sys/block/md0/md/sync_action
-bash: /sys/block/md0/md/sync_action: Permission denied
vagrant@raid-hw3:~$ su root
Password:
root@raid-hw3:/home/vagrant# echo 'check' >/sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/home/vagrant# mdadm --detail --scan /dev/md0
ARRAY /dev/md0 metadata=1.2 name=raid-hw3:0 UUID=24427bcc:8046def4:98a78b51:85034e83
root@raid-hw3:/home/vagrant# rm -r /mnt/raid/
root@raid-hw3:/home/vagrant# ls /mnt/
root@raid-hw3:/home/vagrant# echo 'check' >/sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/home/vagrant# mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
root@raid-hw3:/home/vagrant# umount /mnt/raid
umount: /mnt/raid: no mount point specified.
root@raid-hw3:/home/vagrant# umount /dev/md0
umount: /dev/md0: not mounted.
root@raid-hw3:/home/vagrant# mdadm --stop /dev/md0
mdadm: stopped /dev/md0
root@raid-hw3:/home/vagrant# mdadm /dev/md0 --fail /dev/sdc1
mdadm: error opening /dev/md0: No such file or directory
root@raid-hw3:/home/vagrant# echo 'check' >/sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: No such file or directory
root@raid-hw3:/home/vagrant# mdadm /dev/md0 --fail /dev/sdc1
mdadm: error opening /dev/md0: No such file or directory
root@raid-hw3:/home/vagrant# lsblk
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0  40G  0 disk
└─sda1   8:1    0  40G  0 part /
sdb      8:16   0  10M  0 disk
sdc      8:32   0   5G  0 disk
└─sdc1   8:33   0   5G  0 part
sdd      8:48   0   3G  0 disk
└─sdd1   8:49   0   3G  0 part
root@raid-hw3:/home/vagrant# cat /proc/mdstat
Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10]
unused devices: <none>
root@raid-hw3:/home/vagrant# mdadm --assemble /dev/md0 /dev/sdc1 /dev/sdd1
mdadm: /dev/md0 has been started with 2 drives.
root@raid-hw3:/home/vagrant# mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
root@raid-hw3:/home/vagrant# mdadm --detail --scan | awk '/ARRAY/ {print}' >> /etc/mdadm/mdadm.conf
root@raid-hw3:/home/vagrant# nano /etc/fstab
root@raid-hw3:/home/vagrant# mkdir /mnt/raid
mkdir: cannot create directory ‘/mnt/raid’: File exists
root@raid-hw3:/home/vagrant# ls /mnt/raid
file1  file2  file3  lost+found
root@raid-hw3:/home/vagrant# mdadm --examine /dev/sdc1 /dev/sdb1 /dev/sdd1
/dev/sdc1:
          Magic : a92b4efc
        Version : 1.2
    Feature Map : 0x0
     Array UUID : 24427bcc:8046def4:98a78b51:85034e83
           Name : raid-hw3:0  (local to host raid-hw3)
  Creation Time : Sun Apr  3 19:31:55 2022
     Raid Level : raid0
   Raid Devices : 2

 Avail Dev Size : 10473472 (4.99 GiB 5.36 GB)
    Data Offset : 10240 sectors
   Super Offset : 8 sectors
   Unused Space : before=10160 sectors, after=0 sectors
          State : clean
    Device UUID : 5e1d95b7:27d3af5e:ccfa8243:b2ddf613

    Update Time : Sun Apr  3 19:31:55 2022
  Bad Block Log : 512 entries available at offset 8 sectors
       Checksum : a3b2e88 - correct
         Events : 0

     Chunk Size : 512K

   Device Role : Active device 0
   Array State : AA ('A' == active, '.' == missing, 'R' == replacing)
mdadm: cannot open /dev/sdb1: No such file or directory
/dev/sdd1:
          Magic : a92b4efc
        Version : 1.2
    Feature Map : 0x0
     Array UUID : 24427bcc:8046def4:98a78b51:85034e83
           Name : raid-hw3:0  (local to host raid-hw3)
  Creation Time : Sun Apr  3 19:31:55 2022
     Raid Level : raid0
   Raid Devices : 2

 Avail Dev Size : 6279168 (2.99 GiB 3.21 GB)
    Data Offset : 10240 sectors
   Super Offset : 8 sectors
   Unused Space : before=10160 sectors, after=0 sectors
          State : clean
    Device UUID : 8215febe:7cb63ad4:50c0537e:f5815ff3

    Update Time : Sun Apr  3 19:31:55 2022
  Bad Block Log : 512 entries available at offset 8 sectors
       Checksum : a12873ca - correct
         Events : 0

     Chunk Size : 512K

   Device Role : Active device 1
   Array State : AA ('A' == active, '.' == missing, 'R' == replacing)
root@raid-hw3:/home/vagrant# update-initramfs -u
update-initramfs: Generating /boot/initrd.img-4.15.0-173-generic
root@raid-hw3:/home/vagrant# cat /proc/mdstat
Personalities : [raid0] [linear] [multipath] [raid1] [raid6] [raid5] [raid4] [raid10]
md0 : active raid0 sdc1[0] sdd1[1]
      8376320 blocks super 1.2 512k chunks

unused devices: <none>
root@raid-hw3:/home/vagrant# echo 'check' > /sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/home/vagrant# su echo 'check' > /sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/home/vagrant# dd if=/dev/zero of=/mnt/file bs=1G count=5
dd: memory exhausted by input buffer of size 1073741824 bytes (1.0 GiB)
root@raid-hw3:/home/vagrant# dd if=/dev/zero of=/mnt/file bs=50M count=5
5+0 records in
5+0 records out
262144000 bytes (262 MB, 250 MiB) copied, 1.21075 s, 217 MB/s
root@raid-hw3:/home/vagrant# nano /etc/fstab
root@raid-hw3:/home/vagrant# mount -a
root@raid-hw3:/home/vagrant# echo 'check' > /sys/block/md0/md/sync_action
bash: /sys/block/md0/md/sync_action: Permission denied
root@raid-hw3:/home/vagrant# mdadm /dev/md0 --fail /dev/sdc1
mdadm: set device faulty failed for /dev/sdc1:  Device or resource busy
root@raid-hw3:/home/vagrant# mdadm --stop /dev/md0
mdadm: Cannot get exclusive access to /dev/md0:Perhaps a running process, mounted filesystem or active volume group?
root@raid-hw3:/home/vagrant# umount /mnt/raid
root@raid-hw3:/home/vagrant# mdadm --stop /dev/md0
mdadm: stopped /dev/md0
root@raid-hw3:/home/vagrant# mdadm --assemble /dev/md0 --fail /dev/sdc1 /dev/sdd1
mdadm: :option --fail not valid in assemble mode
root@raid-hw3:/home/vagrant#